# Configuration for ImageNet
# Acknowledgement:
#  Ref: http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf
#  The scheduling parameters is adapted from Caffe(http://caffe.berkeleyvision.org/)
dev=cpu
data = train
iter = imgbin
  image_list = "./train.lst"
  image_bin  = "./train.bin"
  image_mean = "models/image_mean.bin"
  rand_mirror=1
iter = threadbuffer
iter = end
dev=cpu
eval = train
iter = imgbin
  image_list = "./train.lst"
  image_bin  = "./train.bin"
  image_mean = "models/image_mean.bin"
iter = threadbuffer
iter = end
#model_in = "./models/0045.model"
eval_train = 0

netconfig=start
layer[0->1] = conv
  kernel_size = 5
  stride = 4
  nchannel = 96
  pad = 2
layer[1->2] = relu
layer[2->3] = max_pooling
  kernel_size = 3
  stride = 2
layer[3->4] = conv
  kernel_size = 3
  stride = 2
  nchannel = 192
  pad = 2
layer[4->5] = relu
layer[5->6] = max_pooling
  kernel_size = 3
  stride = 2
layer[6->7] = conv
  kernel_size = 3
  stride = 2
  nchannel = 128
  pad = 2
layer[7->8] = relu
layer[8->9] = max_pooling
  kernel_size = 3
  stride = 2
###############
layer[9->10] = conv
  nchannel = 128
  kernel_size = 3
  pad = 2
layer[10->11] = relu
#############
layer[11->12] = conv
  nchannel = 128
  kernel_size = 3
  pad = 1
layer[12->13] = relu
layer[13->14] = max_pooling
  kernel_size = 3
  stride = 2
layer[14->15] = flatten
layer[15->16] = fullc
  nhidden = 512
layer[16->17] = relu
layer[17->17] = dropout
  threshold = 0.5
layer[17->18] = fullc
  nhidden = 512
layer[18->19] = relu
layer[19->19] = dropout
  threshold = 0.5
layer[19->20] = fullc
  nhidden = 512
layer[20->21] = relu
layer[21->21] = dropout
  threshold = 0.5
layer[21->22] = fullc
  nhidden = 1024
layer[22->23] = relu
layer[23->23] = dropout
  threshold = 0.5
layer[23->24] = fullc
  nhidden = 121
layer[24->24] = softmax
netconfig=end

# evaluation metric
metric = error

max_round = 45
num_round = 45

# input shape not including batch
input_shape = 3,48,48

batch_size = 256

# global parameters in any sectiion outside netconfig, and iter
momentum = 0.9
wmat:lr  = 0.01
wmat:wd  = 0.0005

bias:wd  = 0.000
bias:lr  = 0.02

# all the learning rate schedule starts with lr
lr:schedule = expdecay
lr:gamma = 0.1
lr:step = 10000

save_model=1
model_dir=models

# random config
random_type = xavier
init_sigma = 0.01

# new line
